# Ep.6 共轭梯度法

**总结**：

* 背景知识
  * $G-$正交 / 关于$G$共轭：$\lang\boldsymbol{u},\boldsymbol{v}\rang_G=\boldsymbol{u}G\boldsymbol{v}=0$
  * 扩展子空间定理：对于极小化二次函数的 CG
    * 至多搜索$n$步
    * $\boldsymbol{g}_{k+1}^T\boldsymbol{d}_i=0(i=0\sim k)$（新迭代点的梯度$\boldsymbol{g}_{k+1}$正交于之前所有的搜索方向）
    * **梯度迭代关系**：$\boldsymbol{g}_{k+1}=\boldsymbol{g}_k+\alpha_kG\boldsymbol{d}_k$
* **CG 的定义**
  * 适用：无约束、$G$正定的二次函数（一定是凸优化）
  * 核心思想：找到一个$G-$正交向量组，沿着其各个列向量进行精确线搜索
  * **步长迭代关系**：$\alpha_k=\frac{-\boldsymbol{d}_k^T\boldsymbol{g}_k}{\boldsymbol{d}_k^TG\boldsymbol{d}_k}$
  * **搜索方向迭代关系**：$\boldsymbol{d}_{k+1}=-\boldsymbol{g}_{k+1}+\beta_k\boldsymbol{d}_k$，其中$\beta_{k}=\frac{\|\boldsymbol{g}_{k+1}\|^2_2}{\|\boldsymbol{g}_k\|^2_2}$
* **CG 的步骤**  
  对于极小化无约束的二次函数问题（其中$G$为正定对称矩阵）  
  步骤为：
  1. 初始化操作
     1. 选定初始点$\boldsymbol{x}_0$
     2. 计算其梯度$\boldsymbol{g}_0$  
        如果此时$\boldsymbol{g}=0$，则初始点就是极小点、停止迭代；否则继续。
     3. 确定初始搜索方向$\boldsymbol{d}_0=-\boldsymbol{g}_0$
  2. epoch.$k$（$k$从0开始）
     1. （可选）算一个临时变量$\boldsymbol{p}_k=G\boldsymbol{d}_k$
     2. 计算精确步长$\alpha_k=\frac{\|\boldsymbol{g}_k\|^2}{\boldsymbol{d}_k^T\boldsymbol{p}_k}=\frac{\|\boldsymbol{g}_k\|^2}{\boldsymbol{d}_k^TG\boldsymbol{d}_k}$
     3. 得到下一个迭代点$\boldsymbol{x}_{k+1}=\boldsymbol{x}_k+\alpha_k\boldsymbol{d}_k$
     4. 计算新迭代点的梯度$\boldsymbol{g}_{k+1}=\boldsymbol{g}_{k}+\alpha_k\boldsymbol{p}_k=\boldsymbol{g}_{k}+\alpha_kG\boldsymbol{d}_k$（也可以直接求梯度）  
        如果$\boldsymbol{g}=0$，则找到极小点、停止迭代；否则继续。
     5. 计算 GS 正交化系数$\beta_{k}=\frac{\|\boldsymbol{g}_{k+1}\|^2}{\|\boldsymbol{g}_k\|^2}$
     6. 确定下一个搜索方向$\boldsymbol{d}_{k+1}=-\boldsymbol{g}_{k+1}+\beta_k\boldsymbol{d}_k$
* **CG 的性质**
  * **$n$次停止性**：$m\le n$
  * *梯度与搜索方向的正交性*：$\boldsymbol{g}_k^T\boldsymbol{d}_i=0$
  * *子空间*：$\text{span}\{\boldsymbol{g}_{0\sim k}\}=\text{span}\{\boldsymbol{d_{0\sim k}}\}$，两者表示的子空间相同。
  * **搜索方向的共轭性**：$\boldsymbol{d}_k^TG\boldsymbol{d}_i=0$，搜索方向与之前的方向均$G-$正交
  * **梯度的正交性**：$\boldsymbol{g}_k^T\boldsymbol{g}_i=0$，每次迭代点梯度与之前迭代点梯度正交。
  * **下降性**：$\boldsymbol{d}_k^T\boldsymbol{g}_k=-\|\boldsymbol{g}_k\|^2<0$，即方向导数小于0。
  * 收敛速率
    * 如果$G$有$r$个不同的特征值，则 CG 迭代最多在$r$步终止。
    * 如果$G$的特征值出现在$r$个不同的群，则 CG 迭代将在$r$步后得到问题的近似解。
* 拓展和推广
  * $G$特征值（条件数）不好的二次函数 - 预条件共轭梯度法(PCG)
  * 一般函数 - FR 共轭梯度法

---

“共轭梯度法”是属于“**共轭方向法**”的一种，还有其它不同种类的共轭方向法，不同区别在于产生的共轭方向不同。  
共轭方向法是介于 GD 和 NT 两者之间的一种方法（比 GD 快、没 NT 复杂）。

> **对比 - GD 和 NT 法**：
>
> 两者都属于线搜索法，即对于问题：
> $$
> \underset{\boldsymbol{x}\in\R^n}{\min} f(\boldsymbol{x})
> $$
> 当前迭代点$\boldsymbol{x}_0$（$\nabla f(\boldsymbol{x}_0)\ne0$）。  
> 则步骤为：
>
> 1. 构造搜索方向$\boldsymbol{d}_k$：要求满足函数值下降，即$\boldsymbol{d}_k^T\boldsymbol{g}_k\le0$（$\boldsymbol{g}_k$是梯度或其近似）
> 2. 确定步长$\alpha_k$：可以精确，也可以非精确（如回溯 Armijo 线搜索法）
> 3. 进行迭代：$\boldsymbol{x}_{k+1}=\boldsymbol{x}_k+\alpha_k\boldsymbol{d}_k$
>
> **对于 GD**：
>
> * $\boldsymbol{d}_k=-\nabla f(\boldsymbol{x}_k)$
> * 方法简单：方向直接取负梯度，很好求
> * 效率较低：刚开始算法进展大，但接近极小点时（或说要达到很高精度）会很慢
>
> **对于 NT**：
>
> * $\boldsymbol{d}_k=-\nabla^2 f(\boldsymbol{x}_k)^{-1}\nabla f(\boldsymbol{x}_k)$
> * 效率很高：因为有局部二次收敛性
> * 计算量很大：要求二阶导数、并且还要求其逆（逆矩阵本身很难求）
>
> 而共轭方向法则通常比 GD 快，也比 NT 简单（不用算二阶导数和逆矩阵）

首先先以极小化二次函数为例，后面再推广到一般函数（非二次函数），  
问题形如：
$$
\underset{\boldsymbol{x}\in\R^n}{\min} f(\boldsymbol{x})=\frac{1}{2}\boldsymbol{x}^TG\boldsymbol{x}-\boldsymbol{b}^T\boldsymbol{x}
$$  
其中：$G\in\mathcal{S}^n_{++},\boldsymbol{b}\in\R^n$。

Tip. 如果要从如$f(\boldsymbol{x})=ax_1^2+bx_1x_2+cx_2^2$推出$G$，则$G=\begin{bmatrix}2a&b\\b&2c\end{bmatrix}$（注意$\frac{1}{2}\boldsymbol{x}^TG\boldsymbol{x}$有个$\frac{1}{2}$！）

因为实际运用中有很多“极小化二次函数”的问题（比如牛顿法的方向就是极小化二次函数、或线性最小二乘法），  
共轭梯度法就是以这个问题为背景的，故**共轭梯度法很常用**。

## 一、基本思想

共轭梯度基于这样的**基本思想**：  
每次只改变一个分量（沿着一个轴的方向）进行**精确线搜索**。  
这样，对于$\boldsymbol{x}\in\R^n$，只需要$n$步就能搜索到极小点。

对于二次项没有交叉量（即$x_ix_j(i\ne j)$，只有平方量）的函数，其等高线图形一定是椭圆轴平行于坐标轴的，如下图的$\R^2$示例：  
![没有](<images/image-6.1. 共轭梯度-2.png>)  
此时按照基本思想进行搜索，则只用两步就能到极小值点。  
此时易知：$G$为对角矩阵（非对角线元素为0）。

但如果有交叉量，此时相当于图像发生了旋转，如下图：  
![有](<images/image-6.1. 共轭梯度-3.png>)  
此时再按照坐标轴依次进行精确线搜索，则不能两步到达。

因此对于这种情况，可以考虑进行变换，即令$\boldsymbol{x}=T\boldsymbol{y}$，使得变换后的$\boldsymbol{x}$没有交叉量，即重新变成图1。  
⚠️**但一定注意**：$T$**不是只能为**将图2转回图1的**旋转变化**，也可以为**对称、旋转、缩放、错切这四种组成的复合变换**！。
> 说明 - 如何理解对$f(\boldsymbol{x})$应用变换$\boldsymbol{x}=T\boldsymbol{y}$变成$h(\boldsymbol{y})$：
>
> 注意：因为是$x=Ty$，所以是对$h(y)$上的每一点应用$T$变换，得到$f(x)$。  
> 故$h(\boldsymbol{y})$的图形是$f(\boldsymbol{x})$的图形**进行$T$的逆变换**得到的。
>
> 如：$f(\boldsymbol{x})=\frac14\left(3 x_1^2-2 x_1x_2+3 x_2^2\right)$，图形为  
> ![f 等高线图](<images/image-6.1. 共轭梯度-1.png>)
>
> $T$为逆时针45°变换$T=\begin{bmatrix}\frac{\sqrt2}{2}&-\frac{\sqrt2}{2}\\\frac{\sqrt2}{2}&\frac{\sqrt2}{2}\end{bmatrix}$，  
> 用$\boldsymbol{x}=T\boldsymbol{y}$，即$\begin{pmatrix}x_1\\x_2\end{pmatrix}=\begin{pmatrix}\frac{\sqrt{2}}{2}&-\frac{\sqrt{2}}{2}\\\frac{\sqrt{2}}{2}&\frac{\sqrt{2}}{2}\end{pmatrix}\begin{pmatrix}y_1\\y_2\end{pmatrix}$，即$\begin{array}{l}x_{1}=\frac{\sqrt{2}}2y_1-\frac{\sqrt{2}}2y_2\\x_{2}=\frac{\sqrt{2}}2y_1+\frac{\sqrt{2}}2y_2\end{array}$，  
> 得到$h(\boldsymbol{y})=f(T\boldsymbol{y})=\frac{1}{4}\left(3\left(\frac{\sqrt{2}}{2}y_1-\frac{\sqrt{2}}{2}y_2\right)^2-2(\frac{\sqrt{2}}2y_1-\frac{\sqrt{2}}2y_2)(\frac{\sqrt{2}}2y_1+\frac{\sqrt{2}}2y_2)+3\left(\frac{\sqrt{2}}{2}y_1+\frac{\sqrt{2}}{2}y_2\right)^2\right)=\frac{1}{2}(x_1^2+2x_2^2)$，图形为：  
> ![h 等高线图](<images/image-6.1. 共轭梯度.png>)  
> 所以$h$的图形是由$f$的图形经过$T^{-1}$变换得到。
>
> 因此，要让上方等高线的图2的$f$通过转换得到图1的$h$，**直觉上变换为顺时针**，  
> 但！$T$**应该是逆时针旋转**，这样得到的$h$才是想要的，而非直观上的顺时针旋转矩阵。

原函数变为：$h(\boldsymbol{y})=\frac{1}{2}\boldsymbol{y}^TT^TGT\boldsymbol{y}-\boldsymbol{b}^TT\boldsymbol{y}$  
重点是看$T^TGT$是否为对角矩阵。

令$T=[\boldsymbol{d}_1,\boldsymbol{d}_2,\cdots,\boldsymbol{d}_n]$用列向量表示，  
则：
$$
T^TGT=\begin{bmatrix}\boldsymbol{d}_1^T \\\boldsymbol{d}_2^T \\\cdots \\\boldsymbol{d}_n^T \\\end{bmatrix}G[\boldsymbol{d}_1,\boldsymbol{d}_2,\cdots,\boldsymbol{d}_n]=\begin{bmatrix}\boldsymbol{d}_1^TG\boldsymbol{d}_1 & \cdots  &  \boldsymbol{d}_1^TG\boldsymbol{d}_n \\\cdots & \cdots & \cdots \\\boldsymbol{d}_n^TG\boldsymbol{d}_1 & \cdots  &  \boldsymbol{d}_n^TG\boldsymbol{d}_n \\\end{bmatrix}
$$
*Tip. 对$T^TG$可以理解为$n\times1$的向量和一个数$G$乘，故相当于每一个乘上$G$。*  
要让其为对角矩阵，则对$i\ne j$，$\boldsymbol{d}_i^TG\boldsymbol{d}_j=0$。

此时，对变换后的图形，沿着轴$\boldsymbol{e}_1,\cdots, \boldsymbol{e}_n$进行精确线搜索，则能$n$步找到极小点。  
那么回到原图形$\boldsymbol{x}=T\boldsymbol{y}$，就相当于沿着$T\boldsymbol{e}_i$进行精确线搜索，而$T\boldsymbol{e}_i=\boldsymbol{d}_i$，  
故：相当于找到一个满足条件的$T$后，则相当于在原图形$f(\boldsymbol{x})$中**沿着$T$的各个列分量$\boldsymbol{d}_i$进行精确线搜索**。

![总过程](<images/image-6.1. 共轭梯度-4.png>)  
⚠️一定不要被这个图误导：因为这里只用了旋转变化，故回到$f(\boldsymbol{x})$的搜索方向$\boldsymbol{d}_1,\boldsymbol{d}_2$为垂直正交的。  
但如果还包含缩放、错切等变换，就不一定是正交的。

还需要具有一个观念：即$T$可以为任意的形式，只要满足$\boldsymbol{d}_i^TG\boldsymbol{d}_j=0$（即构造$G-$正交向量组）。  
因此$\boldsymbol{d}_1$可以取任意方向（通常为负梯度方向），只要后面的向量都满足$G-$正交即可。
> 举例 - 一个任意方向构造的 T（即梯度共轭法的过程）：
>
> ![过程图](<images/image-6.1. 共轭梯度-6.png>)
>
> 对于$f(\boldsymbol{x})=\frac14\left(3 x_1^2-2 x_1x_2+3 x_2^2\right)$，其图像如蓝圈所示。  
> 首先选择一个任意初始点$\boldsymbol{x}_0=(2,1)$，其搜索方向定为负梯度方向$\boldsymbol{d}_0=(-2.5,-0.5)$，  
> 精确线搜索得到步长为$\alpha_0=13/17$，则迭代点$\boldsymbol{x}_1(3/34,21/34)$。
>
> 此时利用 GS 正交化方法，可以得到满足$\boldsymbol{d}_1G\boldsymbol{d}_0=0$的为$\boldsymbol{d}_2=(-39/289,-273/289)$，  
> 得到精确步长$\alpha_1=-17/26$，从而迭代到极小点$\boldsymbol{x}_*(0,0)$
>
> 此时得到的$T=\begin{bmatrix}-5/2&-39/289\\-1/2&-273/289\end{bmatrix}$，  
> 可以看到$\boldsymbol{d}_1,\boldsymbol{d}_2$并不正交。

## 二、预备知识

### 1. G-正交 / G共轭

对以前的“内积、（二）范数、正交”的概念进行推广。

> 定义 1 - $G-$内积：
>
> 对于一个**正定对称矩阵**$G\in\mathcal{S}^n_{++}$，向量$\boldsymbol{u},\boldsymbol{v}$，  
> 定义$\boldsymbol{u},\boldsymbol{v}$的$G-$内积为：
> $$
> \langle\boldsymbol{u},\boldsymbol{v}\rangle_G=\boldsymbol{u}^TG\boldsymbol{v}
> $$
>
> Tip. 如果$G$是单位阵$I$，则为内积的定义。

---

> 定义 2 - $G-$范数：
>
> 当$\boldsymbol{u},\boldsymbol{v}$一样时，则可以定义“**$G-$范数**”：
> $$
> \|\boldsymbol{u}\|_G=\sqrt{\lang\boldsymbol{u},\boldsymbol{u}\rang_G}=\sqrt{\boldsymbol{u}^TG\boldsymbol{u}}
> $$
>
> Tip. 当$G$为单位矩阵$I$，则是二范数（欧式范数）。

对于标准二次型$\frac{1}{2}(\boldsymbol{x}-\boldsymbol{a})^TG(\boldsymbol{x}-\boldsymbol{a})$，则可以表示为$\frac{1}{2}||\boldsymbol{x}-\boldsymbol{a}||_G^2$。

---

> 定义 3 - $G-$正交 / 关于$G$共轭：
>
> 如果向量$\boldsymbol{u},\boldsymbol{v}$的$G-$内积为0，  
> 则称：$\boldsymbol{u},\boldsymbol{v}$是$G-$正交的，也称为$\boldsymbol{u},\boldsymbol{v}$关于$G$共轭。
>
> 对于**向量组**$\boldsymbol{d}_1,\cdots,\boldsymbol{d}_k$，如果其两两$G-$正交，  
> 则称：这个向量组是[$G-$正交 / 关于$G$共轭]的。

*这个$G-$正交并不好想出一个几何意义（$\boldsymbol{u}$与经过$G$变换的$\boldsymbol{v}$正交，但$G$并没有很明确的几何意义），只能用数学去理解。*  
最多可以理解为：$\boldsymbol{u},\boldsymbol{v}$在另一个空间（可以记作与$G$有关的空间）中是正交的基向量$\boldsymbol{e}_i$，这个空间经过某个变换$T^{-1}$得到，且$\boldsymbol{u},\boldsymbol{v}$均作为$T$的某列。

---

存在定理：  
对于**不含零**的向量组$\boldsymbol{u}_i$，如果**其$G-$正交**$\Rightarrow$向量组一定**线性无关**（注意，不能反过来说）。  
其逆否命题为：向量组线性相关$\Rightarrow$一定不$G-$正交。

> 证明：
>
> ![证明](<images/image-6.1. 共轭梯度-5.png>)  
> 用反证：先假设线性相关，即要存在非零常数$\alpha$线性组合为0。但找不到，即所有$\alpha_i$均为0。  
> 对于任意的第$i$项，等式左乘$G\boldsymbol{d}_i^T$，其余项均因为$G-$正交变为0，故只剩$\alpha_i\boldsymbol{d}_i^TG\boldsymbol{d}_i$项为0，然后看上面解释即可。

### 2. 扩展子空间定理

*该部分需要在学完[三、1.如何确定步长](#1-如何确定步长)之后再来学习。*  
*该知识用于描述共轭方向法的搜索速度。*

> 总结 - 该定理用人话描述就是：
>
> 对于共轭方向法，对于$\R^n$上初始点$\boldsymbol{x}_0$，  
> 其在每进行一轮迭代$\boldsymbol{x}_{k+1}=\boldsymbol{x}_k+\alpha\boldsymbol{d}_k(k\ge0)$时，都会提高一次搜索空间的维度。  
>
> 刚开始$x_1=x_0+\alpha_0d_0$时，是在一条线上搜索最优点的，如果问题极小点恰好在该线上，则一步就能搜索到；  
> 如果不在这条线上，则$x_2=x_1+\alpha_1d_1$时，则是在$d_0$和$d_1$张成的平面上搜索最优点，如果问题极小点恰好在该平面内，则两步就能搜索到；  
> 如果仍不在，则继续迭代，直到迭代$n$次为$x_n=x_{n-1}=\alpha_{n-1}d_{n-1}$时，则是在$d_0\sim d_{n-1}$张成的空间，即整个$\R^n$空间搜索最优点，  
> 问题极小点一定会在$\R^n$中，故一定能搜索到极小点。
>
> 即：对于$\boldsymbol{x}\in\R^n$，最多搜索$n$步就能找到极小点。

**数学表示为**：

在$\R^n$中，对于不含零的$G-$正交向量组$\boldsymbol{d}_0,\cdots,\boldsymbol{d}_{n-1}$（$G$为极小化二次函数问题的那个二次项矩阵），  
对于共轭方向法，任意初始点$\boldsymbol{x}_0$，迭代$\boldsymbol{x}_{k+1}=\boldsymbol{x}_k+\alpha_k\boldsymbol{d}_k$（其中$\alpha_k=\frac{-\boldsymbol{d}_i^T\boldsymbol{g}_k}{\boldsymbol{d}_i^TG\boldsymbol{d}_i}$）时，  
对任意的$k(k\ge0)$，  
**极小化**在**直线**$\{\boldsymbol{x}_k+\alpha\boldsymbol{d}_k:\alpha\in R\}$上的二次函数$f$，也相当于**极小化**在**仿射集**$\boldsymbol{x}_0+\text{span}\{\boldsymbol{d}_0,\cdots,\boldsymbol{d}_k\}$上的二次函数$f$，  
并且满足$\boldsymbol{g}_{k+1}^T\boldsymbol{d}_i=0(i=0\sim k)$（即**新迭代点$\boldsymbol{g}_{k+1}$的梯度正交于之前所有的搜索方向**）。

可记$L_{k}$为$\boldsymbol{d}_0$到$\boldsymbol{d}_k$这$k$个向量生成的子空间（即就是$\R^k$）。

举特定的例子来说：

* 当$k=0$时：  
  极小化$f(\boldsymbol{x}_0+\alpha_0\boldsymbol{d}_0)$也相当于极小化$x_0+\boldsymbol{d}_0$所代表的直线（即相当于整个搜索空间为过$\boldsymbol{x}_0$的那条直线），  
  并且$\boldsymbol{g}_1$与$\boldsymbol{d}_0$正交（垂直）。
* 当$k=1$时：  
  极小化$f(\boldsymbol{x}_1+\alpha_1\boldsymbol{d}_1)$也相当于极小化$x_0+\{\boldsymbol{d}_0,\boldsymbol{d}_1\}$所代表的平面（即相当于整个搜索空间为过$\boldsymbol{x}_0$的那个平面），  
  并且$\boldsymbol{g}_2$与$\boldsymbol{d}_0,\boldsymbol{d}_1$正交（垂直）。

**定理推论** - 至多迭代$n$步：

如果使用**精确线搜索**的共轭方向法，来极小化 **Hasse 矩阵为正定对称矩阵**$G$的$n$元**二次函数**时，  
**至多迭代$n$步**就能找到函数最小点，停止搜索。

> 证明：
>
> 证明的关键逻辑是：  
> $\boldsymbol{g}_{k+1}^T\boldsymbol{d}_i=0$（梯度与之前的搜索方向都正交）$\Rightarrow$ $\boldsymbol{x}_{k+1}$相当于在仿射集$\boldsymbol{x}_0+L_{k+1}$上极小化$f$ $\Rightarrow$ 至多迭代$n$步
>
> **证1.** $\boldsymbol{g}_{k+1}^T\boldsymbol{d}_i=0$：
>
> 这个要证$\boldsymbol{g}_{k+1}$分别与$\boldsymbol{d}_0,\cdots,\boldsymbol{d}_{k}$正交、这$n$个等式。  
> 首先证$\boldsymbol{g}_{k+1}$与$\boldsymbol{d}_{k}$正交：因为精确线搜索，迭代点的梯度方向一定与当前搜索方向正交，即一定满足$\boldsymbol{g}_{k+1}^T\boldsymbol{d}_k=0$，可见[Ep.3 讲的精确线搜索](../Ep.3%20最优解和算法的基本性质/3.md#1-精确线搜索)
。  
> 对于$\boldsymbol{g}_{k+1}$与$\boldsymbol{d}_i(i=0\sim k-1)$正交的证明：  
> 首先对于$f(\boldsymbol{x})=\frac{1}{2}\boldsymbol{x}^TG\boldsymbol{x}-\boldsymbol{b}^T\boldsymbol{x}$，梯度$\boldsymbol{g}_{k+1}=G\boldsymbol{x}_{k+1}-\boldsymbol{b}=G(\boldsymbol{x}_k+\alpha_k\boldsymbol{d}_k)-\boldsymbol{b}=\boldsymbol{g}_k+\alpha_kG\boldsymbol{d}_k$，即得到**梯度的迭代关系**：
> $$
> \boldsymbol{g}_{k+1}=\boldsymbol{g}_k+\alpha_kG\boldsymbol{d}_k
> $$
>
> 因此证$\boldsymbol{g}_{k+1}$与$\boldsymbol{d}_{i}$正交（$i\in[0,k)$），则  
> $\boldsymbol{g}_{k+1}^T\boldsymbol{d}_i$  
> $=(\boldsymbol{g}_k+\alpha_kG\boldsymbol{d}_k)^T\boldsymbol{d}_i$  
> $=\cdots=(\boldsymbol{g}_{i+1}+\alpha_{i+1}G\boldsymbol{d}_{i+1}+\cdots+\alpha_kG\boldsymbol{d}_k)^T\boldsymbol{d} _i$，展开，并注意$G^T=G$  
> $=\boldsymbol{g}_{i+1}^T\boldsymbol{d}_i+\alpha_{i+1}\boldsymbol{d}_{i+1}^TG\boldsymbol{d}_i+\cdots+\alpha_k\boldsymbol{d}_k^TG\boldsymbol{d}_i$，因为$\boldsymbol{d}_i$与$\boldsymbol{d}_{i+1}\sim\boldsymbol{d}_{k}$为$G-$正交，后面乘项均为0；而$\boldsymbol{g}_{i+1}^T\boldsymbol{d}_i$因为精确线搜索也为0；  
> 故$\boldsymbol{g}_{k+1}^T\boldsymbol{d}_i=0$，得证。
>
> ---
>
> 其余的证明略。  
> 主要直到这个性质——满足条件的共轭方向法最多迭代$n$步即可。

🌟注意“扩展子空间定理”的证明中，涉及到一个关键的“**梯度迭代关系**”：

$$
\boldsymbol{g}_{k+1}=\boldsymbol{g}_k+\alpha_kG\boldsymbol{d}_k
$$

只要函数为二次函数$f(\boldsymbol{x})=\frac{1}{2}\boldsymbol{x}^TG\boldsymbol{x}-\boldsymbol{b}^T\boldsymbol{x}$，按照线搜索格式$\boldsymbol{x}_{k+1}=\boldsymbol{x}_k+\alpha_k\boldsymbol{d}_k$迭代，就有这个梯度迭代关系。

## 三、共轭方向法

> 问题背景：
>
> 对于极小化二次函数问题：
> $$
> \underset{\boldsymbol{x}\in\R^n}{\min} f(\boldsymbol{x})=\frac{1}{2}\boldsymbol{x}^TG\boldsymbol{x}-\boldsymbol{b}^T\boldsymbol{x}
> $$
> 其中$G\in\mathcal{S}^n_{++}$为正定对称矩阵，$\boldsymbol{b}\in\R^n$。
>
> 易知：
>
> * 梯度$\nabla f(\boldsymbol{x})=G\boldsymbol{x}-\boldsymbol{b}$
> * 唯一极小点$\boldsymbol{x}_*=G^{-1}\boldsymbol{b}$。

如果找到一个不含零的$G-$正交向量组$\boldsymbol{d}_0,\cdots,\boldsymbol{d}_{n-1}$，  
则该空间任何一个向量，均可以由该向量组线性表示（因为该向量组满秩线性无关）。  
则对于一初始点$\boldsymbol{x}_0$，其与极小点的差代表的向量$\boldsymbol{x}_*-\boldsymbol{x}_0$，可以由$\boldsymbol{d}_i$线性表示：
$$
\boldsymbol{x}_*-\boldsymbol{x}_0=\alpha_0\boldsymbol{d}_0+\cdots+\alpha_{n-1}\boldsymbol{d}_{n-1}
$$
对于该式**可以理解为$n$步“线搜索”**：  
初始点$\boldsymbol{x}_0$先沿$\boldsymbol{d}_0$方向精确线搜索，然后再沿$\boldsymbol{d}_1$方向精确线搜索，直到沿$\boldsymbol{d}_{n-1}$精确线搜索得到极小点$\boldsymbol{x}_*$。

### 1. 如何确定步长

即：怎么得到精确线搜索的步长$\alpha_k$？

**分析**：

对上述等式同时左乘$\boldsymbol{d}_k^TG$得：
$$
\begin{array}{ll}
 &\boldsymbol{d}_k^TG(\boldsymbol{x}_*-\boldsymbol{x}_0)=\alpha_k\boldsymbol{d}_k^TG\boldsymbol{d}_k \\
 \Rightarrow & \alpha_k=\frac{\boldsymbol{d}_k^TG(\boldsymbol{x}_*-\boldsymbol{x}_0)}{\boldsymbol{d}_k^TG\boldsymbol{d}_k}
\end{array}
$$
但是这种形式并不满足，因为其中$\boldsymbol{x}_*$是我们本身就要求的点，其未知，故需要进一步整理。  
*但这里最好变为与$\boldsymbol{x}_k$有关的形式，故最好不要直接代入$\boldsymbol{x}_*=G^{-1}\boldsymbol{b}$【虽然这也是自己牵强的解释……*

注意到对该等式的理解为“依次做$n$步线搜索”，线搜索格式为$\boldsymbol{x}_{k+1}=\boldsymbol{x}_{k}+\alpha_k\boldsymbol{d}_k$，因此可以表示出第$k$步的迭代点为：
$$
\begin{array}{ll}
 & \boldsymbol{x}_k-\boldsymbol{x}_0=\alpha_0d_0+\alpha_1d_1+\cdots+\alpha_{k-1}d_{k-1} \\
 \xRightarrow{\cdot\boldsymbol{d_k}^TG} & \boldsymbol{d_k}^TG(\boldsymbol{x}_k-\boldsymbol{x}_0)=0
\end{array}
$$

由于为一个0值，故$\boldsymbol{d}_k^TG(\boldsymbol{x}_*-\boldsymbol{x}_0)$可减去该表达式，得到：
$$
\begin{array}{ll}
 & \alpha_k=\frac{\boldsymbol{d}_k^TG(\boldsymbol{x}_*-\boldsymbol{x}_k)}{\boldsymbol{d}_k^TG\boldsymbol{d}_k} \\
 \xRightarrow{\boldsymbol{x}_*=G^{-1}\boldsymbol{b}} & \alpha_k=\frac{\boldsymbol{d}_k^T(\boldsymbol{b}-G\boldsymbol{x}_k)}{\boldsymbol{d}_k^TG\boldsymbol{d}_k} \\
 \xRightarrow{\nabla f(\boldsymbol{x}_k)=G\boldsymbol{x}_k-\boldsymbol{b}} & \alpha_k=\frac{-\boldsymbol{d}_k^T\nabla f(\boldsymbol{x}_k)}{\boldsymbol{d}_k^TG\boldsymbol{d}_k}
\end{array}
$$

这与之前在[Ep.3 中提到的“求解精确线搜索步长”](../Ep.3%20最优解和算法的基本性质/3.md#1-精确线搜索)时得到的形式的一样，  
等价于$\alpha_k=\underset{\alpha_k}{\argmin} f(\boldsymbol{x}_k+\alpha_k\boldsymbol{d}_k)$，即求解$\boldsymbol{x}_k$沿着$\boldsymbol{d}_k$方向这条线上的最小点所取步长（就是精确线搜索形式）。

**总结 - 确定步长的公式为**：
$$
\alpha_k=\frac{-\boldsymbol{d}_k^T\nabla f(\boldsymbol{x}_k)}{\boldsymbol{d}_k^TG\boldsymbol{d}_k}
$$

### 2. 如何得到G-正交向量组

对于共轭方向法，核心思想就是：

* 找到一个$G-$正交向量组$\boldsymbol{d}_0,\cdots,\boldsymbol{d}_k$
* 进行最多$n$步的迭代，迭代公式为$\boldsymbol{x}_{k+1}=\boldsymbol{x}_k+\alpha_k\boldsymbol{d}_k$
* 用精确线搜索确定步长，即$\alpha_k=\frac{-\boldsymbol{d}_k^T\nabla f(\boldsymbol{x}_k)}{\boldsymbol{d}_k^TG\boldsymbol{d}_k}$

那么核心问题就只剩下：**如何找到这个$G-$正交向量组**。  
针对这个问题，有很多不同方法，即不同种类的共轭方向法。  
其中一种则是“共轭梯度法”。

## 四、共轭梯度法

> 说明：
>
> 前面说了：$T$可以有很多种类型（并不一定是旋转矩阵），只要让$\boldsymbol{d}_i$为$G-$正交向量组即可，  
> 因此可以首先取$\boldsymbol{d}_0$为初始点负梯度，然后只要用某方法来构造其余的$\boldsymbol{d}_i$使得其为$G-$正交向量组即可。

共轭梯度法确定$G-$正交向量组的思想是：  
利用已有点$\boldsymbol{x}_{0\sim k}$处的**负梯度向量组**$\boldsymbol{g}_{0\sim k}$，通过 Gram-Schmidt 正交化方法，不断生成$G-$正交组的下一个列向量$\boldsymbol{d}_{k+1}$。

该方法不是事前构造好整个$G-$正交向量组来用，而是**边计算边构造**。

### 1. 迭代求解搜索方向 - Gram-Schmidt 正交化方法

> 推导 - Gram-Schmidt 正交化方法：
>
> 通过在迭代的过程中：
>
> 1. 对于初始点$\boldsymbol{x}_0$（可以取为$\boldsymbol{0}$），其搜索方向$\boldsymbol{d}_0$（$G-$正交向量组的第一个列向量）没有任何限制（或者说目前没有任何信息），可以就取为**初始点负梯度**，即$\boldsymbol{d}_0=-\boldsymbol{g}_0$。  
>    然后按照精确线搜索求得步长$\alpha_0=\frac{-\boldsymbol{d}_0^T\boldsymbol{g}_0}{\boldsymbol{d}_0^TG\boldsymbol{d}_0}$，从而得到下一个迭代点$\boldsymbol{x}_1$。
> 2. 对于第1个迭代点$\boldsymbol{x}_1$，根据“梯度迭代关系”可以得到$\boldsymbol{g}_1=\boldsymbol{g}_0+\alpha_0G\boldsymbol{d}_0$。  
>    又因为精确线搜索，$\boldsymbol{g}_1$正交于$\boldsymbol{d}_0$，则可以使用 Gram-Schmidt 正交化，  
>    该方法令$\boldsymbol{d}_1=-\boldsymbol{g}_1+\beta^{(1)}_0\boldsymbol{d}_0$，其中系数$\beta_0$要使得$\boldsymbol{d}_1^TG\boldsymbol{d}_0=0$（**即$\boldsymbol{d}_1$与$\boldsymbol{d}_0$$G-$正交**）。  
>    得到了方向$\boldsymbol{d}_1$后，自然能求得步长$\alpha_1$，从而得到下一个迭代点$\boldsymbol{x}_2$。
> 3. 对于第2个迭代点$\boldsymbol{x}_2$，又可以得到$\boldsymbol{g}_2=\boldsymbol{g}_1+\alpha_1G\boldsymbol{d}_1$，  
>    此时$\boldsymbol{g}_2$正交与$\boldsymbol{d}_0,\boldsymbol{d}_1$，则使用 Gram-Schmidt 正交化，  
>    令$\boldsymbol{d}_2=-\boldsymbol{g}_2+\beta_0^{(2)}\boldsymbol{d}_0+\beta_1^{(2)}\boldsymbol{d}_1$，其中$\beta_0,\beta_1$要使得$\boldsymbol{d}_2^TG\boldsymbol{d}_0=\boldsymbol{d}_2^TG\boldsymbol{d}_1=0$（**即$\boldsymbol{d}_2$与$\boldsymbol{d}_0,\boldsymbol{d}_1$$G-$正交**）。  
>    之后以此类推……

因此共轭梯度法中的 Gram-Schmidt 正交化方法则是：

1. $\boldsymbol{d}_0=-\boldsymbol{g}_0$
2. 对于任意$k\ge0$，用待定系数法可以求得$\boldsymbol{d}_{k+1}$（因为$\boldsymbol{g}_{k+1}$正交于之前所有的搜索方向$\boldsymbol{d}_i$，即线性无关，故可以用线性组合来扩展新维度），即：
   $$
   \boldsymbol{d}_{k+1}=-\boldsymbol{g}_{k+1}+\sum_{i=1}^k\beta^{(k+1)}_i\boldsymbol{d}_i
   $$  
   使得$\boldsymbol{d}^T_{k+1}G\boldsymbol{d}_i=0$（即**与之前的搜索方向$G-$正交**）  
   注：$\beta$的上标代表一组不同的$\beta$（比如$\beta_1^{(1)}$和$\beta_1^{(2)}$代表不同的$\beta$系数），而不是指数。

🌟**关键 - 如何求解各步中的各个$\beta$**：

> **求解过程**：
>
> 因为要满足$\boldsymbol{d}_{k+1}^TG\boldsymbol{d}_i=0$，可以得到线性方程组：  
> $\forall i\in[0,k],(-\boldsymbol{g}_{k+1}+\sum_{j=1}^k\beta^{(k+1)}_j\boldsymbol{d}_j)^TG\boldsymbol{d_i}=0$。将$G\boldsymbol{d}_i$乘进去，并且$\boldsymbol{d}_j^TG\boldsymbol{d}_i=0(i\ne j)$，对于某个$i$，只有$j=1$时非零，  
> $\Rightarrow -\boldsymbol{g}_{k+1}^TG\boldsymbol{d}_i+\beta^{(k+1)}_i\boldsymbol{d}_i^TG\boldsymbol{d}_i=0$  
> $\Rightarrow \beta_i^{(k+1)}=\frac{-\boldsymbol{g}_{k+1}^TG\boldsymbol{d}_i}{\boldsymbol{d}_i^TG\boldsymbol{d}_i}$
>
> 但这个时候，求$\boldsymbol{d}_{k+1}$需要有$k$个$\beta_i\boldsymbol{d}_i$组合，很难算，  
> 但实际上除了最后一个，其余的$\beta_i$均为0。
>
> $\beta_i^{(k+1)}=\frac{-\boldsymbol{g}_{k+1}^TG\boldsymbol{d}_i}{\boldsymbol{d}_i^TG\boldsymbol{d}_i}$。因为梯度递推公式：$\boldsymbol{g}_{k+1}=\boldsymbol{g}_k+\alpha_kG\boldsymbol{d}_k$，得$G\boldsymbol{d}_i=\frac{\boldsymbol{g}_{i+1}-\boldsymbol{g}_{i}}{\alpha_i}$代入，  
> $\Rightarrow \beta_i^{(k+1)}=\frac{-\boldsymbol{g}_{k+1}^T(\boldsymbol{g}_{i+1}-\boldsymbol{g}_{i})}{\boldsymbol{d}_i^T(\boldsymbol{g}_{i+1}-\boldsymbol{g}_i)}$  
> 每一个$\boldsymbol{d}_i$均可由$\boldsymbol{g}_{0\sim i-1}$线性表示（$\boldsymbol{d}_0=-\boldsymbol{g}_0,\boldsymbol{d}_1=-\boldsymbol{g}_1+\beta\boldsymbol{g}_0$）（即$\boldsymbol{d_{0\sim i}}$与$\boldsymbol{g_{0\sim i}}$张成空间相同），因为$\boldsymbol{g}_{k+1}$与$\boldsymbol{d}_i$正交，故$\boldsymbol{g}_{k+1}$与$\boldsymbol{g}_i$正交。  
> 因此分式上面只有$i=k$时，$\boldsymbol{g}_{k+1}^T\boldsymbol{g}_{i+1}$非零，一旦$i<k$，则分子全为0、$\beta=0$；  
> 对于分母，因为$i=k$时，$\boldsymbol{d}_k^T$正交$\boldsymbol{g}_{i+1}$，故为$\boldsymbol{d}_k^T\boldsymbol{g}_k=(-\boldsymbol{g}_k+\beta^{(k)}_{k-1}\boldsymbol{d}_{i-1})^T\boldsymbol{g}_k=\|\boldsymbol{g}_k\|^2_2$，  
> 故：
> $$
> \beta^{(k+1)}_i=\left\{\begin{array}{l}0 & i<k\\\frac{\|\boldsymbol{g}_{k+1}\|^2_2}{\|\boldsymbol{g}_k\|^2_2} & i=k\end{array}\right.
> $$

最终，$\beta$虽然看着很复杂，但实际上：

$$
\beta_{k}=\frac{\|\boldsymbol{g}_{k+1}\|^2_2}{\|\boldsymbol{g}_k\|^2_2}
$$

则搜索方向迭代公式：

$$
\boldsymbol{d}_{k+1}=-\boldsymbol{g}_{k+1}+\beta_k\boldsymbol{d}_k
$$  
其中$\beta_k$如上式。

> 拓展 - 动量项：
>
> 有时候把$\beta_k\boldsymbol{d}_k$称为动量项，  
> 因为这相当于我们在选择搜索方向时，不式简单的只考虑负梯度方向（GD），而还考虑了之前得搜索方向，进行了一个调整。

此时，**精确步长也可以进行化简**：

$$
\alpha_k=\frac{-\boldsymbol{d}_k^T\boldsymbol{g}_k}{\boldsymbol{d}_k^TG\boldsymbol{d}_k} \\
\Rightarrow \alpha_k=\frac{-(\boldsymbol{g}_k+\beta_{k-1}\boldsymbol{d}_{k-1})\boldsymbol{g}_k}{\boldsymbol{d}_k^TG\boldsymbol{d}_k} \\
\Rightarrow \alpha_k=\frac{\|\boldsymbol{g}_k\|^2_2}{\boldsymbol{d}_k^TG\boldsymbol{d}_k}
$$

### 🌟2. 方法定义（迭代步骤）

> 问题背景 - 极小化二次函数问题：
>
> $$
> \min f(\boldsymbol{x})=\frac{1}{2}\boldsymbol{x}^TG\boldsymbol{x}-\boldsymbol{b}^T\boldsymbol{x}
> $$
> 其中$G\in\mathcal{S}^n_{++}$、$\boldsymbol{b}\in\R^n$。

则共轭梯度法的步骤为：

1. 初始化操作
   1. 选定初始点$\boldsymbol{x}_0$
   2. 计算其梯度$\boldsymbol{g}_0$  
      如果此时$\boldsymbol{g}=0$，则初始点就是极小点、停止迭代；否则继续。
   3. 确定初始搜索方向$\boldsymbol{d}_0=-\boldsymbol{g}_0$
2. epoch.$k$（$k$从0开始）
   1. （可选）算一个临时变量$\boldsymbol{p}_k=G\boldsymbol{d}_k$
   2. 计算精确步长$\alpha_k=\frac{\|\boldsymbol{g}_k\|^2}{\boldsymbol{d}_k^T\boldsymbol{p}_k}=\frac{\|\boldsymbol{g}_k\|^2}{\boldsymbol{d}_k^TG\boldsymbol{d}_k}$
   3. 得到下一个迭代点$\boldsymbol{x}_{k+1}=\boldsymbol{x}_k+\alpha_k\boldsymbol{d}_k$
   4. 计算新迭代点的梯度$\boldsymbol{g}_{k+1}=\boldsymbol{g}_{k}+\alpha_k\boldsymbol{p}_k=\boldsymbol{g}_{k}+\alpha_kG\boldsymbol{d}_k$（也可以直接求梯度）  
      如果$\boldsymbol{g}=0$，则找到极小点、停止迭代；否则继续。
   5. 计算 GS 正交化系数$\beta_{k}=\frac{\|\boldsymbol{g}_{k+1}\|^2}{\|\boldsymbol{g}_k\|^2}$
   6. 确定下一个搜索方向$\boldsymbol{d}_{k+1}=-\boldsymbol{g}_{k+1}+\beta_k\boldsymbol{d}_k$

伪代码如下：  
![伪代码](<images/image-6.1. 共轭梯度-7.png>)

### 3. 算法复杂性

* 迭代次数复杂性：$O(n)$（最多$n$次迭代结束）
* 计算复杂性：$O(n^2)$（最复杂的就是矩阵向量乘，最多为$n*n$次元素相乘）  
  并且对于稀疏矩阵，该复杂性会进一步减小，可见下图。
* 空间复杂性：  
  对于特大规模但稀疏的$G$，其不需要记录矩阵$G$（而 NT 或其它方法需要存储$G$，可能因为要计算梯度需要完整$G$的信息）  
  只需要按稀疏矩阵记录方式，然后计算得到$G\boldsymbol{d}_k$即可，如下图：  
  ![稀疏矩阵](<images/image-6.1. 共轭梯度-8.png>)

### 4. 计算举例

![举例](<images/image-6.1. 共轭梯度-9.png>)

### 5. 性质总结

*这里是总结了在共轭梯度法的各种推理和证明过程当中得到的一些性质。*

对于 CG,如果其迭代$m+1$次就到了极小点，则对于之前的$m$次迭代，$k=1,\cdots,m$，存在以下性质：  

* **$n$次停止性**：$m\le n$
* *梯度与搜索方向的正交性*：$\boldsymbol{g}_k^T\boldsymbol{d}_i=0$  
  来源于扩展子空间定理。
* *子空间*：$\text{span}\{\boldsymbol{g}_{0\sim k}\}=\text{span}\{\boldsymbol{d_{0\sim k}}\}$，两者表示的子空间相同。  
  *拓展 - $\boldsymbol{g}_0$的$k$阶 Krylov 子空间$\mathcal{K}_k(G,\boldsymbol{g}_0)$：代表这样一个子空间，其中$\boldsymbol{g}_i$为正交基、$\boldsymbol{d}_i$为$G-$正交基。*
* **搜索方向的共轭性**：$\boldsymbol{d}_k^TG\boldsymbol{d}_i=0$，搜索方向与之前的方向均$G-$正交
* **梯度的正交性**：$\boldsymbol{g}_k^T\boldsymbol{g}_i=0$，每次迭代点梯度与之前迭代点梯度正交  
  是因为梯度与之前的搜索方向正交，再由子空间相同可得，  
  *详细证明可见上面的“关键 - 如何求解各步中的各个$\beta$”。*
* **下降性**：$\boldsymbol{d}_k^T\boldsymbol{g}_k=-\|\boldsymbol{g}_k\|^2<0$，即方向导数（等式左侧）小于0。  
  故满足线搜索的“搜索方向必须是下降方向”的要求。

### 6. 收敛速率

更具体的，CG 最大是迭代$n$次就终止，  
但也可能会提前终止，其取决于二次函数$G$的特征值：

* 如果$G$有$r$个不同的特征值，  
  则 CG 迭代最多在$r$步终止。
* 如果$G$的特征值出现在$r$个不同的群（即特征值可能有很多个，但都聚集在几堆里），  
  则 CG 迭代将在$r$步后得到问题的近似解（就是$r$步后会很接近解）。

如下图所示：  
![特征值影响迭代速度](<images/image-6.1. 共轭梯度-13.png>)  
当$G$的特征值为均匀分布时，迭代速度如虚线所示，很慢；  
而当特征值分布成 5 个群时，迭代速度如实现所示，5 步后就逼近最优解了。

### 7. 拓展 - 预条件共轭梯度法(PCG)

*只用了解这个思想即可。*

上面提到，$G$的特征值的分布会影响迭代速度，  
故类似于 GD，通过**变量替换**，可以将$G$的特征值变成几个群，则能提高收敛速率。  
该方法称为“预条件共轭梯度法”。

令：$\boldsymbol{x}=T\boldsymbol{y}$，  
则原问题变为：$\min h(\boldsymbol{y})=\frac{1}{2}\boldsymbol{y}^TT^TGT\boldsymbol{y}-(T^T\boldsymbol{b})^T\boldsymbol{y}$

预条件，则是构造一个非奇异矩阵$T$，让$T^TGT$有良好的特征值结构。  
![举例](<images/image-6.1. 共轭梯度-14.png>)  
然后用共轭梯度法极小化$h(\boldsymbol{y})$。

但是搜索过程中不用对$\boldsymbol{y}$进行搜索，还是对$\boldsymbol{x}$进行搜索，不过部分变量更新时要变：  
![PCG](<images/image-6.1. 共轭梯度-15.png>)  
其中$M=(TT^T)^{-1}$（虽然不知道原因，但也不用特别记）。

*最后有个例子，可以看 PPT.6 "conjugategradient" 的 P17~18。*

## 五、推广到一般函数

对针对二次函数的共轭梯度法进行推广，  
即问题背景变为：

> 问题背景：
>
> $$
> \underset{\boldsymbol{x}\in\R^n}{\min} f(\boldsymbol{x})
> $$
>
> 其中$f$为任意函数。

对原共轭梯度法需要修改的地方有：

* 梯度：梯度计算跟以前二次函数不一样，故伪代码的行 1,7 肯定不行，要有一个专门子程序计算梯度。
* 步长：精确步长也不能像以前一样计算（以前计算是建立在二次函数的基础上的），也要进行替换。  
* *搜索方向更新系数$\beta_k$*：这个系数原本也是针对二次函数优化问题而求得的。

将这几个进行相应修改后，便可以对极小化一般函数的问题运用共轭梯度法。

### 1. FR 共轭梯度法

FR 共轭梯度法伪代码：  
![FR 共轭梯度法](<images/image-6.1. 共轭梯度-10.png>)

**修改之处**：

* 梯度：用实际的梯度公式计算$\nabla f(\boldsymbol{x})$
* 步长：用非精确线搜索的方法计算  
  如图采用的是[Wolfe 准则](../Ep.3%20最优解和算法的基本性质/3.md#3-wolfe-准则)，其中$\sigma$为“精确系数”，  
  原本要求$\sigma\in(\rho,1)$，其越小越精确，故这里限制小于$0.5$。
* 系数$\beta_k$：仍然简单的采用原来共轭梯度法的计算方法，记为$\beta_k^{FR}$。  
  但这样肯定效果不好，但胜在简单。

### 2. 其他版本的共轭梯度法

针对系数$\beta_k$，还有很多种不同的修改方法，即其他版本的共轭梯度法，如下图：  
![其他版本](<images/image-6.1. 共轭梯度-11.png>)  
如果$f$是原本的二次函数（严格凸的二次函数），并采用精确线搜索，则这四种系数算出来都是一样的。

* 对于第一个$\beta_k^{PRP}$，则相比于原来的（$\beta_k^{FR}$）分母没变、分子变了。  
* 而对于一般函数，$\boldsymbol{g}_{k+1}-\boldsymbol{g}_k$可能为负数，为了保证$\beta>0$，故出现了第二个$\beta_k^+$，  
  而当$\beta_k^+=0$（$\beta_k^{PRP}<0$）时，则可以看成“重新开始”，因为$\boldsymbol{d}_{k+1}=-\boldsymbol{g}_{k+1}+\beta\boldsymbol{d}_k$，即跟$\boldsymbol{d}_0$一样取为负梯度。

其中：$FR-GC$（采用$\beta^{FR}$）的理论分析最完善；$PRP-GC$的实际表现最好。

### 3. 各版本的数值表现

![数值表现](<images/image-6.1. 共轭梯度-12.png>)  
其中"$n$"是矩阵规模、"it"是迭代次数、"f-g"是计算函数和梯度的次数、"mod"是针对 PRP 中$\beta<0$的次数（即 PRP+ 需要调整的次数）。

其设置的**终止条件**为：
$$
\|\boldsymbol{g}_k\|_{\infty}<10^{-5}(1+|f(\boldsymbol{x}_k)|)
$$

有两个借鉴的点：

1. 其运用的是无穷范数，而不是通常的二范数。  
   因为当规模$n$很大时，对于二范数即便单个元素的平方值很小，但累加后仍可能很大，即二范数与规模$n$有关；  
   但无穷范数只取分量绝对值最大的，与$n$无关。
2. 并且运用的是“相对终止准则”$10^{-5}(1+|f(\boldsymbol{x}_k)|)$，  
   即最小值$|f(\boldsymbol{x}_k)|$如果很大的话，则允许更大的误差，故终止条件可以更宽松；  
   如果最小值接近于$0$，则还原成“绝对终止准则”。
