# 

最优化问题(SCO)

## 基本概念

* 可行解
* 可行域$S$
* 全局极小点$x_*$
* 最优值$f_*$: $f_*=f(x_*)$
* 局部(相对)极小点

对于 MP 问题解的情况：

1. $S=\emptyset$: $f_*=+\infty$
2. $S\ne\emptyset$: 
   1. 无(下)界: $f_*=-\infty$
   2. 有(下)界($f_*\in\mathbb{R}$): 
      1. 有最优解: $f_*=f(x_*)$
      2. 无解

## 解的存在性

> 如果$S$是非空紧集（有界闭集），且$f$在$S$上连续，则$f$在$S$上能取到最大值和最小值。

*对于优化问题，基本上都要保证$f$连续。*

## 全局极小点和局部极小点

* 理想：求解全局极小点
* 实际：可以求解局部极小点
  1. 函数具有“凸性” -> 局部极小点 <=> 全局极小点
  2. 有范围约束 -> 区间只有局部极小点

## 类型

1. 根据是否有约束
   * 无约束优化
   * 约束优化
2. 根据离散或连续
   * 离散优化: 如$X=\{0,1\}^n$ -> 0-1规划
   * **连续优化**: 如$X=[0,1]^n$,$\mathbb{R}^n$
3. 根据是否线性
   * 线性优化: 优化函数$f$是线性函数
   * 非线性优化

求解优化问题需要先确定优化函数类型，然后寻找对应方法。

### 线性优化

$$
\text{minimize} \quad c^Tx \\
\text{subject to} \quad a^T_ix\le b_i (i=1,\cdots,m)
$$

不等式也可以写成矩阵形式$Ax\le B$。

### 二次优化

在线性优化的基础上加上一个二次函数

$$
\sum_{i=1}^n\sum_{j=1}^nq_{ij}x_ix_j
$$

可写作$x^TQx$，其中$Q\in S^n$（$S^n$表示$n*n$的对称矩阵）。

### 半定规划

$$
\text{minimize} \quad b^Tx \\
\text{subject to} \quad C-\sum_{i=1}^m y_iA_i \succeq 0
$$

*需要学习：半正定概念*

矩阵$X$半正定 <=> 主子式非负  
*主子式即所有的$n$阶行列式*

## 表述示例里的技巧

* 分段线性优化（如最大化极小值），可以转化为线性优化  
  $\text{maximize}\quad min... \to \text{maximize}\quad Z \quad s.t. Z\le min...$，然后$Z\le min...$转化为若干个约束条件
* 数据拟合  
  已知$m$个$a_i,b_i$，求拟合的函数$f(x)=\vec{a}^Tx+t$，其中$\vec{a}\in\mathbb{R}^n$  
  1. $m\ge n$ - 样本数大于待定参数个数  
     目标：求残差向量最小  
     方法：
     * 最小二乘法（二维范数）
     * 极小化绝对偏差之和（一维范数），等价于线性规划
     * 极小化最大绝对偏差（极限范数），等价于线性规划
   2. $m\ll n$ - 样本数远小于待定参数个数  
      存在先验知识：$\vec{x}$是稀疏向量（很多元素为 0）  
      引入“零范数”概念：$||x||_0=|\{j:x_j=0, j=1,\cdots,n\}|$
      * 样本（观测数据）无噪声
        $$
        \text{minimize} ||x||_0 \\
        \text{subject to} \vec{A}\vec{x}=\vec{b}
        $$
      * 有噪声
        $$
        \text{minimize} \vec{A}\vec{x} - \vec{b} \\
        \text{subject to} ||x||_0 < k
        $$

      上述均为组合优化，很困难，故通常采用“凸松弛”的方法，将$||x||_0 \to ||x||_1$。